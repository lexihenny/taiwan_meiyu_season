{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER,LATITUDE_FORMATTER\n",
    "import os,errno\n",
    "import sys\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from scipy.ndimage.measurements import label\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import geopy.distance\n",
    "%matplotlib inline\n",
    "\n",
    "dir2='/thorncroftlab_rit/ahenny/rain/'\n",
    "dir1='/thorncroftlab_rit/ahenny/rain/US/ghcnd_all/'\n",
    "dir='/thorncroftlab_rit/ahenny/rain/DISSERTATION_SCRIPTS_RESULTS/'\n",
    "#This script plots WNP TC tracks in the 7 days before specified dates (e.g. AR-dominant EP days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.open_dataset(dir+'ls_extreme_rain_taiwan_99_80.nc')\n",
    "p=ds['large_scale_extreme_rain_all']#total rainfall on ER days\n",
    "dates=pd.DatetimeIndex(ds.time.values)\n",
    "dates=pd.DatetimeIndex(dates).values\n",
    "print(dates)\n",
    "\n",
    "ds6=xr.open_dataset(dir+'IBTrACS.WP.v04r00.nc')\n",
    "print(ds6.lat.description)\n",
    "wind_tc=ds6.usa_wind\n",
    "lat_tc=ds6.lat\n",
    "lon_tc=ds6.lon\n",
    "#nature_tc=ds6.nature\n",
    "ds7=xr.open_dataset(dir+'ibtracs_wp_time.nc')\n",
    "years_tc=ds7.years\n",
    "months_tc=ds7.months\n",
    "days_tc=ds7.days\n",
    "hours_tc=ds7.hours\n",
    "nature_tc=ds7.nature#1 if tropical, 0 if not\n",
    "print(nature_tc)\n",
    "print(hours_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds4=xr.open_dataset(dir+'taiwan_ep_days_stats_var95_newar.nc')\n",
    "ar_yesno4=ds4['ar_yesno'].values.tolist()\n",
    "ivt_yesno4=ds4['ivt_yesno'].values.tolist()\n",
    "tc_yesno4=ds4['tc_yesno'].values.tolist()\n",
    "other_yesno4=ds4['other_yesno'].values.tolist()\n",
    "tc_linked_ar_yesno4=ds4['tc_linked_ar_yesno'].values.tolist()\n",
    "tc_linked_ivt_yesno4=ds4['tc_linked_ivt_yesno'].values.tolist()\n",
    "tc_remnant_linked_ivt_yesno4=ds4['ivt_tc_remnants_yesno'].values.tolist()\n",
    "tc_remnant_ar_combo_yesno4=ds4['ar_tc_remnant_combo_yesno'].values.tolist()\n",
    "tc_remnant_linked_ar_yesno4=ds4['tc_remnant_linked_ar_yesno'].values.tolist()\n",
    "tc_remnants_yesno4=ds4['tc_remnants_yesno'].values.tolist()\n",
    "tc_ar_combo_yesno4=ds4['tc_ar_combo_yesno'].values.tolist()\n",
    "\n",
    "zipped_t1=list(zip(dates,ar_yesno4))#ar-related = green\n",
    "zipped_t2=list(zip(dates,tc_linked_ar_yesno4))\n",
    "zipped_t3=list(zip(dates,tc_remnant_linked_ar_yesno4))\n",
    "zipped_t4=list(zip(dates,tc_yesno4))#tc-related = blue\n",
    "zipped_t5=list(zip(dates,tc_ar_combo_yesno4))\n",
    "zipped_t6=list(zip(dates,tc_remnant_ar_combo_yesno4))\n",
    "zipped_t7=list(zip(dates,tc_remnants_yesno4))\n",
    "zipped_t8=list(zip(dates,ivt_yesno4))#other IVT-related = grey\n",
    "zipped_t9=list(zip(dates,tc_linked_ivt_yesno4))\n",
    "zipped_t10=list(zip(dates,tc_remnant_linked_ivt_yesno4))\n",
    "zipped_t11=list(zip(dates,other_yesno4))#unspecified = brown\n",
    "\n",
    "dates_t1=[x[0] for x in zipped_t1 if x[1]==1]\n",
    "dates_t2=[x[0] for x in zipped_t2 if x[1]==1]\n",
    "dates_t3=[x[0] for x in zipped_t3 if x[1]==1]\n",
    "dates_t4=[x[0] for x in zipped_t4 if x[1]==1]\n",
    "dates_t5=[x[0] for x in zipped_t5 if x[1]==1]\n",
    "dates_t6=[x[0] for x in zipped_t6 if x[1]==1]\n",
    "dates_t7=[x[0] for x in zipped_t7 if x[1]==1]\n",
    "dates_t8=[x[0] for x in zipped_t8 if x[1]==1]\n",
    "dates_t9=[x[0] for x in zipped_t9 if x[1]==1]\n",
    "dates_t10=[x[0] for x in zipped_t10 if x[1]==1]\n",
    "dates_t11=[x[0] for x in zipped_t11 if x[1]==1]\n",
    "\n",
    "dates_ar=dates_t1+dates_t2+dates_t3\n",
    "dates_tc=dates_t4+dates_t5+dates_t6+dates_t7\n",
    "dates_other=dates_t8+dates_t9+dates_t10+dates_t11\n",
    "\n",
    "dates_t1=pd.DatetimeIndex(dates_t1)\n",
    "dates_t2=pd.DatetimeIndex(dates_t2)\n",
    "dates_t3=pd.DatetimeIndex(dates_t3)\n",
    "dates_t4=pd.DatetimeIndex(dates_t4)\n",
    "dates_t5=pd.DatetimeIndex(dates_t5)\n",
    "dates_t6=pd.DatetimeIndex(dates_t6)\n",
    "dates_t7=pd.DatetimeIndex(dates_t7)\n",
    "dates_t8=pd.DatetimeIndex(dates_t8)\n",
    "dates_t9=pd.DatetimeIndex(dates_t9)\n",
    "dates_t10=pd.DatetimeIndex(dates_t10)\n",
    "dates_t11=pd.DatetimeIndex(dates_t11)\n",
    "\n",
    "dates_ar=pd.DatetimeIndex(dates_ar)\n",
    "dates_tc=pd.DatetimeIndex(dates_tc)\n",
    "dates_other=pd.DatetimeIndex(dates_other)\n",
    "\n",
    "dates_t1=[x+dt.timedelta(hours=-12) for x in dates_t1]\n",
    "dates_t2=[x+dt.timedelta(hours=-12) for x in dates_t2]\n",
    "dates_t3=[x+dt.timedelta(hours=-12) for x in dates_t3]\n",
    "dates_t4=[x+dt.timedelta(hours=-12) for x in dates_t4]\n",
    "dates_t5=[x+dt.timedelta(hours=-12) for x in dates_t5]\n",
    "dates_t6=[x+dt.timedelta(hours=-12) for x in dates_t6]\n",
    "dates_t7=[x+dt.timedelta(hours=-12) for x in dates_t7]\n",
    "dates_t8=[x+dt.timedelta(hours=-12) for x in dates_t8]\n",
    "dates_t9=[x+dt.timedelta(hours=-12) for x in dates_t9]\n",
    "dates_t10=[x+dt.timedelta(hours=-12) for x in dates_t10]\n",
    "dates_t11=[x+dt.timedelta(hours=-12) for x in dates_t11]\n",
    "\n",
    "dates_tc=[x+dt.timedelta(hours=-12) for x in dates_tc]\n",
    "dates_ar=[x+dt.timedelta(hours=-12) for x in dates_ar]\n",
    "dates_other=[x+dt.timedelta(hours=-12) for x in dates_other]\n",
    "\n",
    "years_t1=[x.year for x in dates_t1]\n",
    "years_t2=[x.year for x in dates_t2]\n",
    "years_t3=[x.year for x in dates_t3]\n",
    "years_t4=[x.year for x in dates_t4]\n",
    "years_t5=[x.year for x in dates_t5]\n",
    "years_t6=[x.year for x in dates_t6]\n",
    "years_t7=[x.year for x in dates_t7]\n",
    "years_t8=[x.year for x in dates_t8]\n",
    "years_t9=[x.year for x in dates_t9]\n",
    "years_t10=[x.year for x in dates_t10]\n",
    "years_t11=[x.year for x in dates_t11]\n",
    "\n",
    "years_tc1=[x.year for x in dates_tc]\n",
    "years_ar=[x.year for x in dates_ar]\n",
    "years_other=[x.year for x in dates_other]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e190b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dates_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-marketplace",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "month_dict={'1':'January','2':'February','3':'March','4':'April','5':'May','6':'June','7':'July','8':'August','9':'September','10':'October','11':'November','12':'December'}    \n",
    "proj_map = ccrs.PlateCarree()\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "ax=plt.subplot(1,1,1,projection=proj_map)\n",
    "\n",
    "years_zipped=list(zip(years_tc1,dates_tc))\n",
    "dates_tc_first=[x[1] for x in years_zipped if x[0]<=1999]\n",
    "dates_tc_second=[x[1] for x in years_zipped if x[0]>=2000]\n",
    "years_tc_first=[x[0] for x in years_zipped if x[0]<=1999]\n",
    "years_tc_second=[x[0] for x in years_zipped if x[0]>=2000]\n",
    "\n",
    "years_zipped1=list(zip(years_ar,dates_ar))\n",
    "dates_ar_first=[x[1] for x in years_zipped1 if x[0]<=1999]\n",
    "dates_ar_second=[x[1] for x in years_zipped1 if x[0]>=2000]\n",
    "years_ar_first=[x[0] for x in years_zipped1 if x[0]<=1999]\n",
    "years_ar_second=[x[0] for x in years_zipped1 if x[0]>=2000]\n",
    "\n",
    "years_zipped2=list(zip(years_other,dates_other))\n",
    "dates_other_first=[x[1] for x in years_zipped2 if x[0]<=1999]\n",
    "dates_other_second=[x[1] for x in years_zipped2 if x[0]>=2000]\n",
    "years_other_first=[x[0] for x in years_zipped2 if x[0]<=1999]\n",
    "years_other_second=[x[0] for x in years_zipped2 if x[0]>=2000]\n",
    "\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import pyplot\n",
    "\n",
    "index_list_date=[]\n",
    "dates_choose=dates_other_first\n",
    "years_choose=years_other_first\n",
    "title='Other: 1979-1999'\n",
    "for d in range(len(dates_choose)):\n",
    "#for d in range(2):\n",
    "    date=dates_choose[d]#date is at 18Z automatically. \n",
    "    print(date)\n",
    "    date_range=[date+dt.timedelta(hours=6*x) for x in range(4)]\n",
    "    date_range=pd.DatetimeIndex(date_range).values#date range for IVT selection\n",
    "\n",
    "    year=date.year\n",
    "    check_lat_tc=lat_tc.where(years_tc==year,drop=True)\n",
    "    check_lon_tc=lon_tc.where(years_tc==year,drop=True)\n",
    "    storm_indices=check_lat_tc.storm.values.tolist()\n",
    "    \n",
    "    index_list=[]\n",
    "    for date in date_range:\n",
    "        date=pd.to_datetime(date)\n",
    "        month=date.month\n",
    "        day=date.day\n",
    "        hour=date.hour\n",
    "        \n",
    "        check_lat_tc1=check_lat_tc.where(months_tc==month,drop=True)\n",
    "        check_lat_tc1=check_lat_tc1.where(days_tc==day,drop=True)\n",
    "        check_lat_tc1=check_lat_tc1.where(hours_tc==hour,drop=True)\n",
    "            \n",
    "        check_lon_tc1=check_lon_tc.where(months_tc==month,drop=True)\n",
    "        check_lon_tc1=check_lon_tc1.where(days_tc==day,drop=True)\n",
    "        check_lon_tc1=check_lon_tc1.where(hours_tc==hour,drop=True) \n",
    "        \n",
    "        check_lat_tc_list=[]\n",
    "        check_lon_tc_list=[]\n",
    "        for l in check_lat_tc1.storm.values:\n",
    "            print(l)\n",
    "            check_lat_tc_values=check_lat_tc1.sel(storm=l).values.tolist()\n",
    "            check_lat_tc_values=[x for x in check_lat_tc_values if x>0]\n",
    "\n",
    "            check_lon_tc_values=check_lon_tc1.sel(storm=l).values.tolist()\n",
    "            check_lon_tc_values=[x for x in check_lon_tc_values if x>-360]\n",
    "            \n",
    "            if len(check_lon_tc_values)>0:\n",
    "                lon_tc_single=check_lon_tc_values[0]\n",
    "                lat_tc_single=check_lat_tc_values[0]\n",
    "                \n",
    "                if 116<=lon_tc_single<=126 and 18<=lat_tc_single<=29.5:\n",
    "                    index_list.append(l)\n",
    "                \n",
    "                \n",
    "    index_list=list(set(index_list))\n",
    "    index_list_date.append(index_list)\n",
    "        \n",
    "print(index_list_date)\n",
    "#sys.exit()\n",
    "print('A')\n",
    "for d in range(len(dates_choose)):\n",
    "#for d in range(len(dates_unique)):\n",
    "    print(d)\n",
    "    date=dates_choose[d]#date is at 6Z automatically. \n",
    "    date_day_end=date+dt.timedelta(hours=24)\n",
    "    date_start=date_day_end+dt.timedelta(days=-7)\n",
    "    date_range=[date_start+dt.timedelta(hours=6*x) for x in range(28)]\n",
    "    date_range=pd.DatetimeIndex(date_range).values\n",
    "    year=years_choose[d]\n",
    "    #index_list=index_list_date[d]\n",
    "    \n",
    "    check_lat_tc=lat_tc.where(years_tc==year,drop=True)\n",
    "    check_lon_tc=lon_tc.where(years_tc==year,drop=True)\n",
    "    check_months_tc=months_tc.where(years_tc==year,drop=True)\n",
    "    check_days_tc=days_tc.where(years_tc==year,drop=True)\n",
    "    check_hours_tc=hours_tc.where(years_tc==year,drop=True)\n",
    "    check_nature_tc=nature_tc.where(years_tc==year,drop=True)\n",
    "    check_wind_tc=wind_tc.where(years_tc==year,drop=True)\n",
    "    segs=[]\n",
    "    for i in check_lat_tc.storm.values:\n",
    "        #if i in index_list:\n",
    "        if 1==1:\n",
    "            storm_lat=check_lat_tc.sel(storm=i).values.tolist()\n",
    "            storm_lon=check_lon_tc.sel(storm=i).values.tolist()\n",
    "            storm_month=check_months_tc.sel(storm=i).values.tolist()\n",
    "            storm_day=check_days_tc.sel(storm=i).values.tolist()\n",
    "            storm_hour=check_hours_tc.sel(storm=i).values.tolist()\n",
    "            storm_wind=check_wind_tc.sel(storm=i).values.tolist()\n",
    "            storm_nature=check_nature_tc.sel(storm=i).values.tolist()\n",
    "            storm_month=[x for x in storm_month if x>=0]\n",
    "            storm_day=[x for x in storm_day if x>=0]\n",
    "            storm_hour=[x for x in storm_hour if x>=0]\n",
    "            storm_date=[pd.to_datetime(dt.datetime(year,int(x),int(y),int(z))) for x,y,z in zip(storm_month,storm_day,storm_hour)]\n",
    "            storm_wind=[x for x in storm_wind if x>=0]\n",
    "            zipped_latlon=list(zip(storm_lat,storm_lon,storm_date,storm_wind,storm_nature))\n",
    "            select_week=[x for x in zipped_latlon if x[2] in date_range]\n",
    "            select_lat=[x[0] for x in select_week]\n",
    "            select_lon=[x[1] for x in select_week]\n",
    "            select_wind=[x[3] for x in select_week]\n",
    "            select_nature=[x[4] for x in select_week]\n",
    "            if len(select_week)>0:\n",
    "                for j in range(len(select_week)-1):\n",
    "                    lat_1=select_lat[j]\n",
    "                    lon_1=select_lon[j]\n",
    "                    lat_2=select_lat[j+1]\n",
    "                    lon_2=select_lon[j+1]\n",
    "                    starting_wind=select_wind[j]#in kts\n",
    "                    starting_nature=select_nature[j]\n",
    "                    #now choose color based on category\n",
    "                    if starting_nature==1:\n",
    "                        if starting_wind<=33:\n",
    "                            color='b'\n",
    "                        if 34<=starting_wind<=63:\n",
    "                            color='g'\n",
    "                        if 64<=starting_wind<=82:\n",
    "                            color='yellow'\n",
    "                        if 83<=starting_wind<=95:\n",
    "                            color='orange'\n",
    "                        if 96<=starting_wind<=112:\n",
    "                            color='r'\n",
    "                        if 113<=starting_wind<=136:\n",
    "                            color='darkred'\n",
    "                        if starting_wind>=137:\n",
    "                            color='m'\n",
    "                    else:\n",
    "                        color='k'\n",
    "\n",
    "                    seg=[[lon_1,lat_1],[lon_2,lat_2]]\n",
    "                    ax.plot([lon_1,lon_2],[lat_1,lat_2],transform=ccrs.PlateCarree(),linewidth=5.0,color=color)\n",
    "                    segs.append(seg)\n",
    "\n",
    "ax.coastlines(resolution='10m')\n",
    "ax.add_feature(cfeature.STATES.with_scale('10m'),alpha=0.3)\n",
    "ax.add_feature(cfeature.LAKES.with_scale('50m'))\n",
    "countries = cfeature.NaturalEarthFeature(category='cultural',name='admin_0_boundary_lines_land',scale='50m',facecolor='none')\n",
    "ax.add_feature(countries)\n",
    "ax.set_extent([95,155,5,45],crs=ccrs.PlateCarree())\n",
    "\n",
    "# Define gridline locations and draw the lines using cartopy's built-in gridliner:\n",
    "xticks = [85,90,95,100,105,110,115,120,125,130,135,140,145,150,155,160]\n",
    "yticks = [5,10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\n",
    "ax.tick_params(labelsize=20)\n",
    "g1=ax.gridlines(crs=ccrs.PlateCarree(),draw_labels=True,alpha=0)\n",
    "g1.xformatter=LONGITUDE_FORMATTER\n",
    "g1.yformatter=LATITUDE_FORMATTER\n",
    "g1.xlabel_style={'size':24,'color':'k'}\n",
    "g1.ylabel_style={'size':24,'color':'k'}\n",
    "g1.top_labels=False\n",
    "g1.right_labels=False\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=1.0)\n",
    "#ax.text(0.93, 0.985,'n='+str(len(dates_choose)), transform=ax.transAxes, fontsize=28,verticalalignment='top', bbox=props,zorder=30)\n",
    "ax.text(0.912, 0.985,'n='+str(len(dates_choose)), transform=ax.transAxes, fontsize=28,verticalalignment='top', bbox=props,zorder=30)\n",
    "ax.set_title(title,fontsize=38,pad=10)#2000 - 2019; 1979-1999\n",
    "\n",
    "patch1 = mpatches.Patch(color='b', alpha=1,label='TD')\n",
    "patch2 = mpatches.Patch(color='g', alpha=1,label='TS')\n",
    "patch3 = mpatches.Patch(color='yellow', alpha=1,label='Cat 1')\n",
    "patch4 = mpatches.Patch(color='orange', alpha=1,label='Cat 2')\n",
    "patch5 = mpatches.Patch(color='r', alpha=1,label='Cat 3')\n",
    "patch6 = mpatches.Patch(color='darkred', alpha=1,label='Cat 4')\n",
    "patch7 = mpatches.Patch(color='m', alpha=1,label='Cat 5')\n",
    "patch8 = mpatches.Patch(color='k', alpha=1,label='Non-tropical')\n",
    "\n",
    "legend1=pyplot.legend(handles=[patch1,patch2,patch3,patch4,patch5,patch6,patch7,patch8],loc='upper left',prop={'size':20},fancybox=True, framealpha=1.0)\n",
    "pyplot.gca().add_artist(legend1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(dir+'taiwan_tc_halves_paper_6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dates_ar_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-processing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 June 2020 Environment",
   "language": "python",
   "name": "jun20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
